### Kubernetes learning notes
***************************************

* What is kubernetes ?
=> kubernetes is a open source container orchestration tool designed to automate the deployment, scaling, and management of containerized applications in different deployment environments(physical/virtual/cloud/hybrid).

Containers -> containers are lightweight, portable unit that package an application and its dependencies together into a single unit.

Orchestration -> when you have many containers running across multiple machines, you need a way to manage them - starting, stopping, scaling, updating, and ensuring they stay healthy.

Key features of kubernetes:
********************************
1. Automated deployment and scaling : Automatically deploy and scale/descale application based on demand. Scaling can be done horizontally(increasing no. of nodes/pods/container) or vertically(increasing cpu/ memory)
2. Load balancing (network) : Distributes traffic across pods/containers to ensure reliability and performance.
3. Rolling Updates & Rollbacks :  update application without any downtime and can rollback if something goes wrong
4. Service discovery : Automatically assigns ip addresses and a single DNS name for a set of containers
5. Secret and configuration management : Manages sensitive information like passwords and configuration settings securely.


Basic Components of kubernetes :
************************************
1. Pod - Smallest unit of deployment, in which one or more containers keeps running.
2. Node : A machine(physical/virtual) that runs pods
3. Cluster: A set of nodes manages by k8s
4. Master(Control Plane): manages the cluster and makes global decisions(like scheduling)
5. Worker nodes : nodes which form k8s cluster where pod/container runs
6. kubelet : an agent that runs on each node which helps in the creation of the pod.

Kubernetes Architecture :
****************************

Kubernetes cluster consists of control plane( that we say as master node) and nodes (worker machines)

Control plane(Top layer): 
*****************************
-> Manages the overall cluster and makes global decisions

There are 4 components which runs on kubernetes master node :

1. API Server : It is heart of k8s cluster, all components(controllers, schedulers) interact with the cluster through the API server.It receives RESTful API calls and processes them and then stores the data in the etcd database(in key value pair format). 
    -> As a end user we interact with api server component of k8s master node, whatever kubectl command we fire, command is sent as REST API request to the k8s API server.
    -> Validation of command/manifest file
    -> Authentication and Authorization 
      * Verify the identity of users (authentication)
      * Checks if they have permission to perform the requested action (authorization)

2. etcd  :  is a database (nosql format) that holds all cluster data in key-value pair format. etcd is a distributed, consistent, and highly available key-value store.
   
      -> etcd is a highly available and consistent key-value store that helps in Kubernetes backing store for all the cluster data
      -> Stores all configuration data (Configmaps(non-sensitive data), secrets(encrypted sensitive data)), user info(user roles(rbac), user permissions), node info(node status,             node metrics, node labels, taints and conditions), pod info(pod status, pod metrics, pod lables, spec (configuration like containers, volumes and restart policies)),       
         Replicasets, Deployment, Daemonsets , app versions, no. of replicas, connectivity etc.
  
just adding below lines about etcd for understanding purpose :

    -> Distributes means : Runs across multiple nodes for fault tolerance and high availability.
    -> Strong Consistency - Guarantees that reads always return the most recent write.
    -> High Availability - Can tolerate node failures using leader election and quorum-based writes.

3. Controller manager : is a key component of the control plane that runs controller processes - background loops that monitor the cluster state and make changes to move the current state toward the desired state

-> A controller is a control loop, that watches the state of your cluster through API server and makes changes to ensure actual state matches the desired state.

-> Process that run controller to handle cluster background task
-> It is a daemon(server) that runs in a continuous loop and responsible for gathering information and sending it to API server
-> Responsible for changing the current state of cluster to its desired state

Key function of controller manager : 

The kube-controller manager runs multiple controller in a single process, here are the main ones
1. Node controller - monitors the health of the nodes and manages node lifecycle, mark node as NotReady if node become unresponsive. Evicts pods from failed nodes.
2. Replication controller - ensure the specifies number of pods replicas are always running. Creates or deletes pods as needed
3. Deployment controller - manages rolling updates and rollback for deployments, ensure the desired version of an app is running
4. Endpoint Controller: Manages endpoints for services.
5. Service Account Controller: Manages service accounts. Creates default service accounts for new namespaces. Manages API access tokens for service accounts.
6. Job & CronJob Controllers : Manages one-time and scheduled jobs.Ensures jobs complete successfully or are retried if they fail.

=> How It Works (Simplified Flow):
  -> You define a desired state (e.g., 3 replicas of a pod).
  -> The controller watches the current state via the API server.
  -> If the actual state differs (e.g., only 2 pods running), the controller takes action (e.g., creates a new pod).
  -> It keeps looping to maintain the desired state.

4. Scheduler : The Kubernetes Scheduler is a core component of the control plane responsible for assigning newly created Pods to Nodes in the cluster. It ensures that workloads are placed on the most suitable nodes based on resource availability, constraints, and policies.

 Key Responsibilities of the Scheduler
********************************************
1. Pod Placement
-> When a new Pod is created (but not yet assigned to a Node), the Scheduler Watches for unassigned Pods via the API Server.
-> Selects an appropriate Node for each Pod.
-> Updates the Podâ€™s specification with the chosen Node.

2. Filtering Nodes
-> The Scheduler first filters out Nodes that cannot run the Pod due to:
-> Insufficient CPU, memory, or other resources.
-> Node taints and tolerations.
-> Node selectors or affinity rules.
-> Volume or port conflicts.

3. Scoring Nodes
-> Among the remaining Nodes, it scores them based on:
-> Resource availability (e.g., least loaded).
-> Pod affinity/anti-affinity.
-> Data locality (e.g., for storage).
-> Custom scheduling policies.


Components of Worker node  :
****************************

1. Kubelet : 
-> an agent which runs on each worker nodes in k8s cluster
-> Helps in the creation of pods and ensures the container containers are running inside pod

2. Kube-proxy 
-> Handles all network traffic in k8s cluster
-> routes connection to specific/correct pod and also perform load balancing across pods
-> Kube-Proxy enables Pods to communicate with Services using a stable virtual IP (ClusterIP).

3. Container runtime 
-> The software responsible for running containers (e.g., Docker, containerd, CRI-O).
-> Kubelet uses it to start, stop, and manage containers inside Pods.
-> Responsible for pulling images, starting/stopping containers, and managing storage and networking.


Kubernetes Pod:
**********************
-> smallest unit of deployment in K8S cluster
-> Contains one or more running container
-> Each pod gets its own IP address (internal)
-> New IP address on pod re-creation

=> So in short, a pod does not have stable IP address, its ip address changes frequently on pod deletion/re-creation or restarts, It is not possible to access the application using POD IP everytime, thats where we need kubernetes services. so we need stable IP address to communicate with pods and other resources within cluster, this is where we need kubernets services which provides you a stable endpoint (ClusterIP, DNS name) to access these pods.

Why do we need Kubernetes Services ?
****************************************

1. Pods are empheral 
    -> Pods can be created and destroyed frequently
    -> Each pod gets a new IP address when rec-created
    -> Services provide a stable endpoint (ClusterIP, DNS name) to access these pods

2. Load balancing 
    -> Services distribute traffic across multiple pods(or replica)
    -> Ensures high availability and better resource utilization

3. Service discovery 
    -> Kubernetes assigns a DNS name to each service
    -> Other pods can discover and connect to the service using this name

Types of Kubernetes Services :
*************************************

1. ClusterIP
2. NodePort
3. LoadBalancer
4. Ingress


1. ClusterIP Service - 
    -> It is default service in k8s which is used to internally expose the resources within cluster. It exposes the service on an internal IP in the cluster
    -> This IP is not accessible from outside the cluster.
    -> It allows Pods to communicate with each other using a consistent endpoint, even if the underlying Pods change.

Sample YAML definition file for nginx service at ClusterIP:
--------------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP

Samnple NGINX Deployment YAML :
---------------------------------

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80


2. NodePort Service :
------------------------
-> Expose resources externally (it has a range 30000-32767)
-> NodePort exposes the service on each Nodeâ€™s IP at a static port (the NodePort)
-> You can contact the NodePort service from outside the cluster, by requesting <Node IP>:<Node Port>

-> It allows users to access a service from outside the cluster using the nodeâ€™s IP address and the assigned port.
-> Kubernetes allocates a port from a predefined range (default: 30000â€“32767).
-> This port is open on every node in the cluster.
-> Traffic sent to this port on any node is forwarded to the corresponding service and then to the appropriate Pod.

Sample YAML definition for NOdePort service :
---------------------------------------------------

apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport-service
spec:
  selector:
    app: nginx
  type: NodePort
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30080

When to Use NodePort:
-----------------------------
-> For development or testing environments.
-> When you donâ€™t have a cloud load balancer.
-> When you want direct access to services from outside the cluster.

3. Load Balancer Service : A LoadBalancer service in Kubernetes is a type of service that exposes your application to the internet by provisioning an external load balancer 
-----------------------------
(typically provided by a cloud provider like AWS, Azure, or GCP).

-> Expose resources externally
-> This service will use or dynamically create an external load balancer like a cloud load balancer when running in the cloud. This load balancer gets a public IP address.
-> It forwards external traffic to the Kubernetes service, which then routes it to the appropriate Pods.
-> Cloud provider will provide a mechanism for routing the traffic to the services
-> we can create network load balancer in cloud . cost will be there.

Sample YAML definition file for nginx load balancer:
----------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: nginx-loadbalancer-service
spec:
  selector:
    app: nginx
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80

External Name Service:
------------------------
An ExternalName service in Kubernetes is a special type of service that maps a service name to an external DNS name. It doesnâ€™t create a traditional service proxy or load balancerâ€”instead, it acts like a DNS alias within the cluster.

Sample YAML definition file for external Name 
---------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: external-db
spec:
  type: ExternalName
  externalName: db.example.com


Ingress : is a service which supports path based routing 
**********

Ingress in Kubernetes is an API object that manages external access to services within a cluster, typically over HTTP and HTTPS. It acts as a smart router that controls how requests from outside the cluster are routed to internal services based on rules like hostnames and URL paths.

=> Why Do We Need Ingress?
*********************************
By default, Kubernetes services are only accessible:

    -> Internally via ClusterIP
    -> Externally via NodePort or LoadBalancer, which are limited and not flexible

Ingress solves this by:

    -> Consolidating access under a single IP or domain
    -> Allowing path-based or host-based routing
    -> Supporting TLS termination (HTTPS)
    -> Enabling custom routing rules and authentication

How path based routing works ?
*************************************
1. Ingress Controller 
    -> Listens for incoming HTTP/HTTPS traffic from outside the cluster
    -> responsible for routing external HTTP(S) traffic to the appropriate services inside the Kubernetes cluster.

Popular Ingress Controllers :
********************************
NGINX - Most widely used, flexible and well-documented.
Traefik - Dynamic configuration, good for microservices.
HAProxy - High-performance, enterprise-grade.
Istio Gateway - Part of the Istio service mesh.
AWS ALB Ingress - Integrates with AWS Application Load Balancer.

2. Ingress resource 
    -> Define routing rules based on URL paths (e.g. /api/, /web, /admin)

3. Path rules
    -> Requests to /api are routed to Backend Service A.
    -> Requests to /web go to Backend Service B.
    -> Requests to /admin are sent to Backend Service C.

4. Backend Services
    -> Each service forwards traffic to its associated Pods (e.g., Pod A1, Pod A2).

Benefits of path based routing:
*************************************
-> Efficiently route different parts of an application (e.g. frontend, backend, admin) through a single domain
-> Simplifies traffic management and scaling.
-> Enables microservices architecture with clean separation.

Here's a sample Ingress YAML configuration for path-based routing in Kubernetes:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: example-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: backend-service-a
            port:
              number: 80
      - path: /web
        pathType: Prefix
        backend:
          service:
            name: backend-service-b
            port:
              number: 80
      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: backend-service-c
            port:
              number: 80

Explanation :
*****************
host: The domain name (e.g., myapp.example.com) that routes traffic through this Ingress.
paths: Each path (like /api, /web, /admin) is routed to a different backend service.
rewrite-target: Ensures the path is rewritten correctly when passed to the backend (optional, depends on your use case and ingress controller).































